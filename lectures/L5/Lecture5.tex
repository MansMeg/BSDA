%\documentclass[10pt,handout]{beamer}
\documentclass[10pt]{beamer}
\usepackage{babel} % Anpassa efter svenska. Ger svensk logga.
\usepackage[utf8]{inputenc} % Anpassa efter linux
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\input{../common/lststan} % Stan listing[language=Stan]

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage{../common/beamerthemeUppsala}
%\usetheme{Uppsala}
%\usecolortheme{UU} % Anpassa efter UU:s frger och logga
%\hypersetup{pdfpagemode=FullScreen} % Adobe Reader ska ppna fullskrm
\setbeamertemplate{itemize items}[circle]

% \usepackage{beamerthemesplit}
\usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{graphics}
% \usepackage{graphicx}
% \usepackage{epsfig}
% \usepackage[latin1]{inputenc}
 \usepackage{color}
% \usepackage{fancybox}
% \usepackage{psfrag}
% \usepackage[english]{babel}
 \setbeamertemplate{footline}{\hfill\insertframenumber/\inserttotalframenumber}

% Input new commands
\input{../common/commands.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength{\parskip}{3mm}
\title[]{{\color{black}Bayesian Statistics and Data Analysis \\ Lecture 5}}
\author[]{M{\aa}ns Magnusson \\ Department of Statistics, Uppsala University \\ Thanks to Aki Vehtari, Aalto University}
\date{}

\begin{document}

\frame{\titlepage
% \thispagestyle{empty}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}
  \frametitle{Seminar today at 13.15}

  \begin{itemize}
  \item \uured{Topic}: posteriordb: Testing, Benchmarking and Developing Bayesian Inference Algorithms
  \item \uured{Where}: H317 Ekonomikum
  \item \uured{Speaker} Jakob Torgander, Department of Statistics, Uppsala University
  \item \uured{Opponent} David Broman, EECS, KTH Royal Institute of Technology
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{Assignment 4}

  \begin{itemize}
  \item "More explicit examples of proper weight normalization would help prevent implementation errors in importance sampling."\pause
  \item "$\hat{R}$ diagnostics is mentioned in the information on the assignment" \pause
  \item "It was hard to find information on how to solve the exercises from the book and lectures." \pause
  \item "..., maybe add a testable MCSE function so that we can know we have done it correct." \pause
  \item "it might help if the workload were reduced or if there were more time between assignments" \pause
  \item Minor suggestions and improvements
  \end{itemize}

\end{frame}

\section{Monte Carlo recap}
%\frame{\sectionpage}



\begin{frame}

\frametitle{ It's all about expectations}

  \vspace{-1.5\baselineskip}
   \begin{align*}
     E_{\color{blue} p(\theta|y)}[f(\theta)] & = \int f(\theta) {\color{blue} p(\theta|y)} d\theta,\\
     \text{where} \quad
     {\color{blue} p(\theta|y)} & = \frac{\color{uured}p(y|\theta)p(\theta)}{\color{red} \int p(y|\theta)p(\theta) d\theta}
   \end{align*}
     \uncover<2->{We can easily evaluate ${\color{uured} p(y|\theta)p(\theta)}$ for any $\theta$, but the integral ${\color{red} \int p(y|\theta)p(\theta) d\theta}$ is usually difficult.}

   \uncover<3->{We can use the unnormalized posterior ${\color{uured} q(\theta|y)
     = p(y|\theta)p(\theta)}$, for example, in}
 \begin{itemize}
   \vspace{-0.5\baselineskip}
%    \item<4-> Grid (equal spacing) evaluation with self-normalization
%      \begin{align*}
%        E_{\color{blue} p(\theta|y)}[f(\theta)] \approx
%        \frac{\sum_{s=1}^S \left[f(\theta^{(s)}){\color{uured}q(\theta^{(s)}|y)}\right]}{\sum_{s=1}^S{\color{uured}q(\theta^{(s)}|y)}}
%      \end{align*}
    \item<4-> Monte Carlo methods which can sample from
      ${\color{blue}p(\theta^{(s)}|y)}$ using only
      ${\color{uured}q(\theta^{(s)}|y)}$
         \vspace{-0.5\baselineskip}
      \begin{align*}
        E_{\color{blue} p(\theta|y)}[f(\theta)] \approx \frac{1}{S} \sum_{s=1}^S f(\theta^{(s)})
      \end{align*}
    \end{itemize}

\end{frame}


\begin{frame}

\frametitle{ Monte Carlo}

  \begin{itemize}
  \item Monte Carlo methods we have discussed so far
    \begin{itemize}
    \item Inverse CDF works mainly for 1D \pause
%    \item Analytic transformations work for only certain distributions \pause
%    \item Factorization works only for certain joint distributions
    \item Grid methods works in a few dimensions \pause
    \item Rejection sampling works mostly in 1D (truncation is a special case) \pause
    \item Importance sampling is reliable only in special cases
    \end{itemize}
    \pause
  \item What to do in high dimensions? \pause
    \begin{itemize}
    \item Markov chain Monte Carlo (Ch 11-12) \pause
    \item Laplace, Variational*, EP* (Ch 4, 13*, next course)
    \end{itemize}
  \end{itemize}
\end{frame}


\section{Markov Chain Monte Carlo (MCMC)}
%\frame{\sectionpage}

\begin{frame}

\frametitle{Markov chains}

  \begin{itemize}
  \item<1-> Andrey Markov proved weak law of large numbers and central
    limit theorem for certain dependent-random sequences, which were
    later named \uured{Markov chains}
  \item<2-> The probability of each event depends only on the previous event (or finite number of previous events)
    \[
    p(\theta_t|\theta_{t-1}, \theta_{t-2}, ...) = p(\theta_t|\theta_{t-1})
    \]
%  \item<3-> Markov's one example was the sequence of letters in
%    Pushkin's novel ``Yevgeniy Onegin''
    \item<3-> $T_t(\theta_{t} \mid \theta_{t-1}) \equiv p(\theta_t|\theta_{t-1})$ is usually refered to as the {\color{uured} transition distribution}
    \item<4-> Under some assumptions $p(\theta_t|\theta_{t-1})$ will converge (in total variation) to \emph{one} {\color{uured} stationary distribution} $p(\theta)$
    \item<5-> \uured{Goal in MCMC}: Construct a {\color{uured} transition distribution} with $p(\theta|y)$ as the {\color{uured} stationary distribution}
  \end{itemize}

\end{frame}


%\begin{frame}

% TODO: A more formal introduction + an example

%\frametitle{ Markov chain}
%
%  \begin{itemize}
%  \item Example of a simple Markov chain on black board
%  \end{itemize}
%
%\end{frame}


\begin{frame}

\frametitle{Markov chain Monte Carlo (MCMC)}

  \begin{itemize}
  \item Produce draws $\theta_{(t)}$ given $\theta_{(t-1)}$ from a
    Markov chain, with {\color{uured}stationary distribution} $p(\theta|y)$
    \begin{itemize}
    \item<2->[+] generic
    \item<2->[+] combine sequence of easier Monte Carlo draws to form a Markov chain
    \item<3->[+] converges (in total variation) to $p(\theta|y)$ as $t\rightarrow\infty$
    \item<4->[+] central limit theorem holds for expectations
    \item<5->[-] draws are dependent
    \item<5->[-] construction of an \uured{efficient} Markov chains is not always easy
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}

\frametitle{MCMC summary}

  \begin{itemize}
  \item Random variables $\theta_1,\theta_2,\ldots$ where $\theta_t$ depends only on the previous $\theta_{(t-1)}$
    \begin{equation*}
      p(\theta_t|\theta_1,\ldots,\theta_{(t-1)})=p(\theta_t|\theta_{(t-1)})
    \end{equation*}
    \pause
  \item Chain has to be initialized with some starting point $\theta_0$ \pause
  % \item Transition distribution $T_t(\theta_t|\theta_{t-1})$ (may depend on $t$) \pause
  \item Choose a transition distribution so the
    {\color{uured}stationary distribution} of the Markov chain is $p(\theta|y)$
  \end{itemize}

\end{frame}

\subsection{Gibbs sampling}
\frame{\subsectionpage}

\begin{frame}

\frametitle{Gibbs sampling}

  \begin{itemize}
  \item Alternate sampling from conditional distributions
  \item Basic algorithm, for $j \in \{1,...,J\}$ {
      \begin{align*}
         \text{sample $\theta_{j,t}$ from} \quad & p(\theta_j|\theta_{-j,t-1}, y),\\
      \text{where} \quad
          \theta_{-j,t-1} = & (\theta_{1,t},\dots,\theta_{j-1,t},
          \theta_{j+1,t-1},\dots,\theta_{J,t-1})
      \end{align*}
      }
  \item Will converge (in total variation) to $p(\theta|y)$ as $N\rightarrow\infty$\pause
  \item $j$ can be multiple (blocked) parameters
  \item 1D sampling ($|j|=1$) is generally easy\pause
  \item Popular for \uured{discrete parameters}
%  \item Related to the (stochastic) EM algorithm
  \end{itemize}
\end{frame}

\begin{frame}

\frametitle{Example: Bivariate Normal using Gibbs}

\[
p(\theta \mid y) \;\sim\; \mathcal{N}\!\left( \bar{y}, \tfrac{1}{n}\Sigma \right).
\]
where $\Sigma$ is known and $\theta \in \mathcal{R}^2$
\vspace{3mm}
\pause

Using \uured{Gibbs sampling}:\\
\vspace{3mm}
Given starting values \((\theta_1^{(0)}, \theta_2^{(0)})\), for \(t = 1,2,\dots\):

\[
\theta_1^{(t)} \;\sim\; \mathcal{N}\!\left(
\bar{y}_1 + \frac{\rho}{\sigma_{2}}\big(\theta_2^{(t-1)} - \bar{y}_2\big),\;
\frac{1}{n}\Big(\sigma_{1} - \frac{\rho^2}{\sigma_{2}}\Big)
\right),
\]

\[
\theta_2^{(t)} \;\sim\; \mathcal{N}\!\left(
\bar{y}_2 + \frac{\rho}{\sigma_{1}}\big(\theta_1^{(t)} - \bar{y}_1\big),\;
\frac{1}{n}\Big(\sigma_{2} - \frac{\rho^2}{\sigma_{1}}\Big)
\right).
\]

\end{frame}





\begin{frame}

\frametitle{Gibbs sampling}

    \vspace{-.5\baselineskip}
     \begin{center}
       \includegraphics[width=5cm]{figs/Gibbs1.pdf}
     \end{center}
    \vspace{-.5\baselineskip}
     \begin{center}
       \href{https://github.com/MansMeg/BSDA/blob/main/lectures/L5/figs/gibbs_example.gif}{demo}
     \end{center}
\end{frame}

\begin{frame}

\frametitle{ Gibbs sampling}

  \vspace{-0.5\baselineskip}
  \begin{itemize}
  \item With \uured{conditionally conjugate} priors, the sampling from
    the conditional distributions is easy for wide range of models
  \item<2-> BUGS / WinBUGS / OpenBUGS / JAGS
  \item<3-> No algorithm parameters to tune
  \item<4-> For not so easy conditionals, use  e.g. inverse-CDF
  \item<5-> Several parameters can be updated in blocks ({\em blocking})
  \item<6-> Slow if parameters are highly dependent in the posterior...
  \end{itemize}

\end{frame}

\begin{frame}
\frametitle{Gibbs sampling}

    \vspace{-.5\baselineskip}
     \begin{center}
       \includegraphics[width=5cm]{figs/Gibbs2.pdf}
     \end{center}
    \vspace{-.5\baselineskip}
     \begin{center}
       \href{https://github.com/MansMeg/BSDA/blob/main/lectures/L5/figs/gibbs_example_correlated.gif}{demo}
     \end{center}
\end{frame}

\begin{frame}

\frametitle{Sampling conditional vs joint}

  \begin{itemize}
  \item How about sampling $\theta$ jointly?
    \begin{itemize}
    \item e.g. it is easy to sample from multivariate normal
    \end{itemize}
    \item<2-> Can we use that to form a Markov chain?
  \end{itemize}

\end{frame}

\subsection{Metropolis-Hastings}
\frame{\subsectionpage}

\begin{frame}

\frametitle{The Metropolis algorithm}

  \begin{itemize}
  \item Algorithm
    \begin{itemize}
      \item[1.] starting point $\theta^0$
      \item[2.] $t=1,2,\ldots$
        \begin{itemize}
        \item[(a)] pick a proposal $\theta^{*}$ from a {\color{uured} proposal distribution}
          $J_t(\theta^{*}|\theta_{t-1})$. \\
          (Proposal distribution has to be symmetric, i.e.\\
          $J_t(\theta_a|\theta_b)=J_t(\theta_b|\theta_a)$, for all
          $\theta_a,\theta_b$)
        \item<2->[(b)] calculate acceptance ratio
          \begin{equation*}
            r=\frac{p(\theta^{*}|y)}{p(\theta_{t-1}|y)}
          \end{equation*}
          \vspace{-6mm}
        \item<3->[(c)] set
          \begin{equation*}
            \theta_t=
            \begin{cases}
              \theta^{*} & \text{with probability $\min(r,1)$}\\
              \theta_{t-1} & \text{otherwise}
            \end{cases}
          \end{equation*}
          \uncover<4>{
          ie, if $p(\theta^{*}|y)>p(\theta_{t-1}|y)$ accept the proposal always \\
          \hspace{0.4cm}and otherwise accept the proposal with probability $r$}
      \end{itemize}
      \vspace{-1.5\baselineskip}
    \item<5-> rejection of a proposal increments the time $t$ also by one\\
      ie, the new state is the same as previous
      \item<6-> step c is executed by generating a random number from
        $\U(0,1)$
      \item<7-> $p(\theta^*|y)$ and $p(\theta_{t-1}|y)$ have the same
        normalization terms, and thus instead of $p(\cdot|y)$,
        unnormalized $q(\cdot|y)$ can be used, { \color{uured} as the normalization terms cancel out}!
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}

\frametitle{ Metropolis algorithm}

  \begin{itemize}
  \item Example: one bivariate observation $(y_1,y_2)$
    \begin{itemize}
    \item bivariate normal distribution with unknown mean and known
      covariance
       \begin{equation*}
         \left.
         \begin{pmatrix}
           \theta_1\\
           \theta_2
         \end{pmatrix}
         \right| y \sim
         \N\left(
           \begin{pmatrix}
             y_1\\
             y_2
           \end{pmatrix},
           \begin{pmatrix}
             1 & \rho\\
             \rho & 1
         \end{pmatrix}
       \right)
       \end{equation*}
     \item proposal distribution
       $J_t(\theta^{*}|\theta_{t-1})=\N(\theta^{*}|\theta_{t-1},\sigma_p^2)$
     \end{itemize}
   \end{itemize}

  \center
  \href{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard}{demo}

\end{frame}

 \begin{frame}

\frametitle{Why Metropolis algorithm works}

  \begin{itemize}
  \item Intuitively more draws from the higher density areas as
    jumps to higher density are always accepted and only some of the
    jumps to the lower density are accepted
    \vspace{5mm}
    \pause
  \item Theoretically
    \begin{itemize}
    \item[1.] Prove that simulated series is a Markov chain
      which has unique stationary distribution
    \item[2.] Prove that this stationary distribution is the desired target distribution $p(\theta|y)$
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}

\frametitle{Why Metropolis algorithm works}

  \begin{itemize}
  \item[1.] Prove that simulated series is a Markov chain
    which has unique stationary distribution
    \begin{itemize}
    \item[a)] irreducible
      \begin{itemize}
      \item<2->[=] positive probability of eventually reaching any
        state from any other state
      \end{itemize}
    \item[b)] aperiodic
      \begin{itemize}
      \item<3->[=] aperiodic (return times are not periodic)
      \item<3->[-] holds for a random walk on any proper distribution (except for trivial exceptions)
      \end{itemize}
    \item[c)] recurrent / not transient
      \begin{itemize}
      \item<4->[=] probability to return to a state $i$ is 1 as $T\rightarrow \infty$
      \item<4->[-] holds for a random walk on any proper distribution (except for trivial exceptions)
      \end{itemize}
    \end{itemize}
  \end{itemize}

\end{frame}


\begin{frame}

\frametitle{Why Metropolis algorithm works}

  \begin{itemize}
  \item[2.] Prove that this stationary distribution is the desired target distribution $p(\theta|y)$: see book

  \begin{itemize}
  \item Show \emph{detailed balance} with respect to
$p(\theta|y)$:
\[
p(\theta|y)\, T(\theta|\theta') = p(\theta'|y)\, T(\theta'|\theta),
\quad \forall \theta, \theta' .
\]

Here, $T(\theta'|\theta)$ denotes the one-step transition probability (or density).
\vspace{3mm} \pause
\item Intuition:
\begin{itemize}
\item Think of $p(\theta|y)$ as the ``mass'' of probability at state $\theta$.\pause
\item $p(\theta|y) P(\theta, \theta')$ is the ``flow'' of mass from $\theta$ to $\theta'$. \pause
\item \uured{Detailed balance}: the flow from $\theta$ to $\theta'$ equals the flow back
from $\theta'$ to $\theta$ --- nothing accumulates or leaks.
\end{itemize}
\end{itemize}
\pause
\vspace{3mm}
\centering{\uured{More indepth in a proper Markov Theory course!}}



%    \begin{itemize}
%    \item[-] consider starting algorithm at time $t-1$ with a draw
%      $\theta_{t-1} \sim p(\theta|y)$
%    \item<2->[-] consider any two such points $\theta_a$ and $\theta_b$ drawn
%      from $p(\theta|y)$ and labeled so that
%      $p(\theta_b|y)\geq p(\theta_a|y)$
%    \item<3->[-] the unconditional probability density of a transition from $\theta_a$ to $\theta_b$ is
%      \vspace{-0.5\baselineskip}
%      \begin{equation*}
%        p(\theta_{t-1}=\theta_a,\theta_{t}=\theta_b)=
%        p(\theta_a|y)J_t(\theta_b|\theta_a),
%      \end{equation*}
%      \vspace{-1\baselineskip}
%    \item<4->[-] the unconditional probability density of a transition from $\theta_b$ to $\theta_a$ is
%      \vspace{-0.5\baselineskip}
%      \begin{eqnarray*}
%        p(\theta_{t}=\theta_a,\theta_{t-1}=\theta_b) & = &
%        p(\theta_b|y)J_t(\theta_a|\theta_b)\left(\frac{p(\theta_a|y)}{p(\theta_b|y)}\right)\\
%        \pause &  = &  p(\theta_a|y)J_t(\theta_a|\theta_b),
%      \end{eqnarray*}
%      \uncover<5->{
%      which is the same as the probability of transition from $\theta_a$ to $\theta_b$,
%      since we have required that $J_t(\cdot|\cdot)$ is symmetric}
%      \pause
%    \item<6->[-] since their joint distribution is symmetric, $\theta_t$ and
%      $\theta_{t-1}$ have the same marginal distributions, and so
%      $p(\theta|y)$ is the stationary distribution of the Markov chain of $\theta$
%    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}

\frametitle{Metropolis-Hastings algorithm}

  \begin{itemize}
  \item Generalization of Metropolis algorithm for \uured{non-symmetric} proposal distributions
    \begin{itemize}
    \item acceptance ratio includes ratio of proposal distributions
      \begin{equation*}
        r =
        \frac{p(\theta^{*}|y)/J_t(\theta^{*}|\theta_{t-1})}{p(\theta_{t-1}|y)/J_t(\theta_{t-1}|\theta^{*})} \pause =
        \frac{p(\theta^{*}|y)J_t(\theta_{t-1}|\theta^{*})}{p(\theta_{t-1}|y)J_t(\theta^{*}|\theta_{t-1})}
      \end{equation*}
    \end{itemize}
  \end{itemize}

\end{frame}

% \begin{frame}

% \frametitle{ Metropolis-Hastings algorithm}

%   \begin{itemize}
%   \item More efficient proposal distributions
%     \item e.g. Langevin-Hastings algorithm which uses gradient information to make proposals
%         \begin{itemize}
%         \item more likely to propose values with higher density
%         \end{itemize}
%   \end{itemize}

% \end{frame}

\begin{frame}

\frametitle{ Metropolis-Hastings algorithm}

  \begin{itemize}
  \item Ideal proposal distribution is the distribution itself
    \begin{itemize}
    \item $J(\theta^{*}|\theta)\equiv p(\theta^{*}|y)$ for all
      $\theta$
    \item acceptance probability is $1$
    \item independent draws
    \item not usually feasible
    \end{itemize}
  \item<2-> Good proposal distribution resembles the target distribution
    \begin{itemize}
    \item if the shape of the target distribution is unknown, usually
      normal or $t$ distribution is used
    \end{itemize}
  \item<3-> After the proposal distribution shape has been selected, it is important to select the scale
    \begin{itemize}
    \item small scale \\$\rightarrow$ many steps accepted, but the chain moves slowly due to small steps
    \item big scale \\$\rightarrow$ long steps proposed, but many of
      those rejected and again chain moves slowly
    \end{itemize}
    \begin{center}
  \href{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard}{demo}
  \end{center}
  \item<4-> Generic rule for rejection rate is 60-90\% %(but depends on dimensionality and a specific algorithm variation)
\end{itemize}

\end{frame}

\begin{frame}

\frametitle{Gibbs sampling as a special case}

  \begin{itemize}
  \item Specific case of Metropolis-Hastings algorithm
    \begin{itemize}
    \item single updated (or blocked)
    \item proposal distribution is the conditional distribution\\
      $\rightarrow$ proposal and target distributions are same\\
      $\rightarrow$ acceptance probability is $1$
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}

\frametitle{ Metropolis}

  \begin{itemize}
  \item Usually doesn't scale well to high dimensions
    \begin{itemize}
    \item if the shape doesn't match the whole distribution, the efficiency drops
%    \item demo11\_2\\
      \vspace{1\baselineskip}
      \hspace{-1cm}\includegraphics[width=4cm]{figs/Metrop2.pdf}\includegraphics[width=4cm]{figs/Metrop3.pdf}
    \end{itemize}
  \end{itemize}

\end{frame}

\section{MCMC Diagnostics}
\frame{\sectionpage}

\begin{frame}

\frametitle{What we want to know}

  \begin{enumerate}
  \item Has the chains \uured{converged} to the posterior distribution?
  \pause
  \item How many \uured{efficient} samples do I have?
  \end{enumerate}

\end{frame}

\subsection{Warm-up}
\frame{\subsectionpage}

\begin{frame}

\frametitle{Warm-up}

  \begin{itemize}
  \item Asymptotically chain spends the $\alpha$\% of time where
    $\alpha$\% posterior mass is
    \uncover<2->{
      \begin{itemize}
      \item but in finite time the initial part of the Markov chain may be
        non-representative \\
        \hspace{2cm}\includegraphics[width=4cm]{figs/Metrop1.pdf}
      \end{itemize}
      }
      \vspace{-.5\baselineskip}
    \item<3-> Warm-up period = (non-representative) draws from the beginning of the Markov chain
    \begin{itemize}
      \item remove warm-up before using samples for inference
      \item warm-up may include phase for adapting algorithm parameters
      \end{itemize}
    \item<4-> Also called {\color{uured} burn-in}
  \end{itemize}

\end{frame}

\subsection{Convergence}
\frame{\subsectionpage}

\begin{frame}

\frametitle{Assesing convergence}

  \vspace{-0.5\baselineskip}
  \begin{itemize}
  \item Several Markov chains make convergence diagnostics easier
  \pause
    \item Start chains from different starting points -- preferably overdispersed
      \begin{center}
  \vspace{-0.5\baselineskip}
      \includegraphics[width=6cm]{figs/10chains1.pdf}
    \end{center}
  \vspace{-0.5\baselineskip}
    \item<2-> Remove warm-up draws and run chains long enough
  \end{itemize}

\end{frame}

\begin{frame}

\frametitle{Several chains}

      \begin{center}
      \only<1>{\includegraphics[width=8cm]{figs/10chains2.pdf}}
      \only<2->{\includegraphics[width=8cm]{figs/10chains3.pdf}}\\
      \uncover<3->{Visual convergence check is not sufficient}
    \end{center}

\end{frame}



\begin{frame}[fragile]

\frametitle{ $\widehat{R}$: comparison of within and between variances of the chains}

  \begin{itemize}
  \item $\widehat{R}$ or {\color{uured} potential scale reduction factor} (PSRF)
  \item Compare means and variances of the chains\\
    \uncover<2->{W = within chain variance estimate\\
    var\_hat\_plus = total variance estimate\\}
    \vspace{1\baselineskip}
    \only<1>{\hspace{-0.5cm}\phantom{\includegraphics[width=8cm]{figs/10chains_rhat1.pdf}}}
    \only<2>{\hspace{-0.5cm}\includegraphics[width=8cm]{figs/10chains_rhat1.pdf}}
    \only<3>{\hspace{-0.5cm}\includegraphics[width=8cm]{figs/10chains_rhat2.pdf}}
    \only<4>{\hspace{-0.5cm}\includegraphics[width=8cm]{figs/10chains_rhat3.pdf}}
  \end{itemize}

\end{frame}

\begin{frame}

\frametitle{ $\widehat{R}$}

  \begin{itemize}
  \item $M$ chains, each having $N$ draws
  \item<2-> Within chains variance $W$
    \begin{equation*}
      W=\frac{1}{M}\sum_{m=1}^M s^2_m ,\text{ where }
      s^2_m=\frac{1}{N-1}\sum_{n=1}^N (\theta_{nm}-\bar{\theta}_{.m})^2
    \end{equation*}
  \item<3-> Between chains variance $B$
    \begin{align*}
      B&=\frac{N}{M-1}\sum_{m=1}^M
      (\bar{\theta}_{.m}-\bar{\theta}_{..})^2,\\
      &\text{ where } \bar{\theta}_{.m}=\frac{1}{N}\sum_{n=1}^N \theta_{nm}, \,
      \bar{\theta}_{..}=\frac{1}{M}\sum_{m=1}^M\bar{\theta}_{.m}
    \end{align*}
    %\vspace{-6mm}
    \begin{itemize}
      \item<4-> $B/N$ is variance of the means of the chains
    \end{itemize}
    \vspace{2mm}
  \item<5-> Estimate total variance
    $\var(\theta|y)$ as a weighted mean of $W$ and $B$
    \begin{equation*}
      \widehat{\var}^{+}(\theta|y) = \frac{N-1}{N}W+\frac{1}{N}B
    \end{equation*}
  \end{itemize}

\end{frame}


\begin{frame}

\frametitle{ $\widehat{R}$}

  \begin{itemize}
  \item Estimate total variance
    $\var(\theta|y)$ as a weighted mean of $W$ and $B$
    \begin{equation*}
      \widehat{\var}^{+}(\theta|y) = \frac{N-1}{N}W+\frac{1}{N}B
    \end{equation*}
    \vspace{-0.5\baselineskip}
    \begin{itemize}
    \item this \emph{overestimates} marginal posterior variance if the
      starting points are overdispersed
    \end{itemize}
    \vspace{0.5\baselineskip}
  \item<2-> Given finite $N$, $W$ \emph{underestimates} marginal posterior variance
    \begin{itemize}
    \item single chains have not yet visited all points in the distribution
    \item when $N\rightarrow\infty, \quad \E(W)\rightarrow \var(\theta|y)$
    \end{itemize}
    \vspace{0.5\baselineskip}
  \item<3-> As $\widehat{\var}^{+}(\theta|y)$ overestimates and $W$ underestimates,
    compute
    \begin{equation*}
      \widehat{R}=\sqrt{\frac{\widehat{\var}^{+}}{W}}
    \end{equation*}
\end{itemize}

\end{frame}


%\begin{frame}[fragile]

%\frametitle{ $\widehat{R}$}

%  \begin{itemize}
%  \item BDA3: $\widehat{R}$ aka {\em potential scale reduction factor} (PSRF)
%  \item Compare means and variances of the chains\\
%    W = within chain variance estimate\\
%    var\_hat\_plus = total variance estimate\\
%    \vspace{1\baselineskip}
%    \only<1>{\hspace{-0.5cm}\includegraphics[width=8cm]{figs/10chains_rhat1.pdf}}
%    \only<2>{\hspace{-0.5cm}\includegraphics[width=8cm]{figs/10chains_rhat2.pdf}}
%    \only<3>{\hspace{-0.5cm}\includegraphics[width=8cm]{figs/10chains_rhat3.pdf}}
%  \end{itemize}

%\end{frame}

%\begin{frame}

%\frametitle{ $\widehat{R}$}

%  \begin{equation*}
%      \widehat{R}=\sqrt{\frac{\widehat{\var}^{+}}{W}}
%    \end{equation*}
%    \begin{itemize}
%    \item<1-> Estimates how much the scale could reduce if $N\rightarrow\infty$
%    \item<1-> $\widehat{R}\rightarrow 1$, when $N\rightarrow\infty$
%    \item<1-> If $\widehat{R}$ is big (e.g., $R>1.01$), keep sampling
%    \item<2-> If $\widehat{R}$ close to 1, it is still possible that chains have not converged
%      \begin{itemize}
%      \item if starting points were not overdispersed
%      \item distribution far from normal (especially if infinite variance)
%      \item just by chance when $N$ is finite
%      \end{itemize}
%    \end{itemize}

%\end{frame}

%\begin{frame}[fragile]

%\frametitle{$\widehat{R}$}

%  \begin{itemize}
%  \item Additional $\widehat{R}$ methods to assess convergence
%  \item Split-$\widehat{R}$
%  \begin{itemize}
%    \item Examines {\it mixing} and {\it stationarity} of chains
%    \item To examine stationarity chains are split to two parts: compare means and variances of the split chains
%  \end{itemize}
%  \pause
%  \item Rank normalized $\widehat{R}$
%  \begin{itemize}
%    \item Does not requires that the target distribution has finite mean and variance
%  \end{itemize}
%  \end{itemize}

%\end{frame}


\subsection{$S_\text{eff}$, MCSE, and autocorrelation}
\frame{\subsectionpage}


\begin{frame}

\frametitle{MCMC draws are dependent}

  \begin{itemize}
    \item Monte Carlo estimates still valid (central limit theorem)
      \begin{align*}
        E_{\color{blue} p(\theta|y)}[f(\theta)] \approx \frac{1}{S} \sum_{s=1}^S f(\theta^{(s)})
      \end{align*}
    \item Estimation of Monte Carlo error is more difficult
      \begin{itemize}
        \item evaluation of {\it effective} sample size, $S_\text{eff}$.
      \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}

\frametitle{MCMC Autocorrelation}

  \begin{itemize}
  \item Auto correlation function
    \begin{itemize}
    \item describes the correlation given a certain lag
    \item can be used to compare efficiency of MCMC methods
    \end{itemize}
  \end{itemize}
%\vspace{.5cm}
%   \begin{center}
%       \includegraphics[scale=.8,clip]{kuva11_1}
%   \end{center}
\end{frame}

\begin{frame}

\frametitle{Autocorrelation}

  \vspace{-0.5\baselineskip}
  \includegraphics[width=4cm]{figs/Metrop1.pdf}
  \uncover<2->{\includegraphics[width=5cm]{figs/Metrop1trace.pdf}\\}
  \uncover<3->{\includegraphics[width=5cm]{figs/Metrop1acf.pdf}}

\end{frame}

\begin{frame}

\frametitle{Autocorrelation}

  \vspace{-0.5\baselineskip}
  \includegraphics[width=4cm]{figs/Metrop2.pdf}
  {\includegraphics[width=5cm]{figs/Metrop2trace.pdf}\\}
  {\includegraphics[width=5cm]{figs/Metrop2acf.pdf}}

\end{frame}

\begin{frame}

\frametitle{Autocorrelation}

  \vspace{-0.5\baselineskip}
  \includegraphics[width=4cm]{figs/Metrop3.pdf}
  {\includegraphics[width=5cm]{figs/Metrop3trace.pdf}\\}
  {\includegraphics[width=5cm]{figs/Metrop3acf.pdf}}

\end{frame}

\begin{frame}

\frametitle{Autocorrelation}

  \begin{itemize}
  \item The autocorrleation can be used to estimate Monte Carlo error in case of MCMC
  \item For expectation $\bar{\theta}$
    \begin{equation*}
      \Var[\bar{\theta}] = \frac{\sigma^2_\theta}{S_\text{eff}}
    \end{equation*}
    where $S_\text{eff}=S/\tau$, and $\tau$ is sum of autocorrelations
    \begin{itemize}
      \item<2-> $\tau$ describes how many dependent draws correspond to one independent draw
      \item<3-> Here $S=NM$ (in BDA3 $N=nm$ and $n_\text{eff}=N/\tau$)
      \item<4-> BDA3 focuses on $S_\text{eff}$ and not the Monte Carlo error directly
%        new R-hat paper discusses more about MCSEs for different quantities
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}

\frametitle{Autocorrelation}

  \begin{itemize}
  \item Estimation of the autocorrelation using several chains
    \begin{equation*}
      \hat{\rho}_n=1-\frac{W - \frac{1}{M}\sum_{m=1}^M \hat{\rho}_{n,m}}{2\widehat{\var}^{+}}
    \end{equation*}
    where $\hat{\rho}_{n,m}$ is autocorrelation at lag $n$ for chain $m$
%  \item<2-> This combines $\widehat{R}$ and autocorrelation estimates
%    \begin{itemize}
%    \item takes into account if the chains are not mixing (the chains have not converged)
%    \end{itemize}
  \item<2-> BDA3 has slightly different and less accurate equation. The
    above equation is used in Stan 2.18+
  \item<3-> Compared to a method which computes the autocorrelation
    from a single chain, the multi-chain estimate has smaller variance
 \end{itemize}
\end{frame}



\begin{frame}

\frametitle{Estimating $\tau$}

  \begin{itemize}
  \item Estimation of $\tau$
    \begin{align*}
      \tau = 1 + 2 \sum_{t=1}^\infty \hat{\rho}_t
    \end{align*}
    where $\hat{\rho}_t$ is empirical autocorrelation
    \begin{itemize}
    \item<2-> empirical autocorrelation function is noisy %and thus
%      estimate of $\tau$ is noisy
    \item<2-> noise is larger for longer lags (less observations)
    \item<3-> less noisy estimate is obtained by truncating
    \begin{align*}
      \hat{\tau} = 1 + 2 \sum_{t=1}^T \hat{\rho}_t
    \end{align*}
    \end{itemize}
%    \item<4-> As $\tau$ is estimated from a finite number of draws,
%      it's expectation is overoptimistic
%      \begin{itemize}
%      \item if $\hat{\tau}>MN/20$ then the estimate is unreliable
%
%      \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}

\frametitle{Geyer's adaptive window estimator of $\tau$}

  \begin{itemize}
  \item Truncation $T$ can be decided adaptively
    \begin{itemize}
    \item for stationary, irreducible, recurrent Markov chain
    \item let $\Gamma_m=\rho_{2m}+\rho_{2m+1}$, which is sum of two
      consequent autocorrelations
    \item $\Gamma_m$ is positive, decreasing and convex function of $m$
    \end{itemize}
    \vspace{0.5\baselineskip}
  \item<2-> Initial positive sequence estimator (Geyer's IPSE)
      \begin{itemize}
        \item Choose the largest $m$ so, that all values of the sequence
        $\hat{\Gamma}_1, \ldots, \hat{\Gamma}_m$ are positive
      \end{itemize}
  \vspace{0.5\baselineskip}
      \includegraphics[width=6cm]{figs/Metrop1acf.pdf}
  \end{itemize}
\end{frame}

% Gibbs1 neff=252, N=2001
% Gibbs2 neff=12, N=2001, Rhat 1.11
% Metrop1 neff=194, N=5000
% Metrop2 neff=48, N=5000
% Metrop3 neff=81, N=5000

\begin{frame}

 \frametitle{Effective sample size, $S_\text{eff}$}

   Effective sample size $\ESS = S_\text{eff} \approx S/\hat{\tau}$\\
   \uncover<2->{
  \makebox[10cm][t]{
%    \hspace{-.7cm}
     \begin{minipage}{10cm}
     \includegraphics[width=4.5cm]{figs/Metrop1trace.pdf}
     \includegraphics[width=4.5cm]{figs/Metrop1acf.pdf}\\
     \includegraphics[width=4.5cm]{figs/Metrop1mcerr.pdf}
     \hspace{0cm}
     \begin{minipage}[t][4cm][t]{4.5cm}
       \vspace{-2.5cm}
       \begin{align*}
         \hat{\tau} & = 1 + 2 \sum_{t=1}^T \hat{\rho}_t\\
                 & \approx 24
       \end{align*}
               \begin{align*}
         \hat{S}_\text{eff} & = \frac{4500}{24} \approx  188
       \end{align*}
     \end{minipage}
   \end{minipage}
   }
   }

\end{frame}

\begin{frame}

 \frametitle{Effective sample size, $S_\text{eff}$}

   Effective sample size $\ESS = S_\text{eff} \approx S/\hat{\tau}$\\
  \makebox[10cm][t]{
%    \hspace{-.7cm}
     \begin{minipage}{10cm}
     \includegraphics[width=4.5cm]{figs/Metrop2trace.pdf}
     \includegraphics[width=4.5cm]{figs/Metrop2acf.pdf}\\
     \includegraphics[width=4.5cm]{figs/Metrop2mcerr.pdf}
     \hspace{0cm}
     \begin{minipage}[t][4cm][t]{4cm}
       \vspace{-2.5cm}
       \begin{align*}
         \hat{\tau} & = 1 + 2 \sum_{t=1}^T \hat{\rho}_t\\
                 & \approx 104
       \end{align*}
               \begin{align*}
         \hat{S}_\text{eff} & = \frac{4500}{104} \approx  43
       \end{align*}
     \end{minipage}
   \end{minipage}
   }

\end{frame}


\begin{frame}

\frametitle{Effective sample size, $S_\text{eff}$}

   Effective sample size $\ESS = S_\text{eff} \approx S/\hat{\tau}$\\
  \makebox[10cm][t]{
%    \hspace{-.7cm}
     \begin{minipage}{10cm}
     \includegraphics[width=4.5cm]{figs/Metrop3trace.pdf}
     \includegraphics[width=4.5cm]{figs/Metrop3acf.pdf}\\
     \includegraphics[width=4.5cm]{figs/Metrop3mcerr.pdf}
     \hspace{0cm}
     \begin{minipage}[t][4cm][t]{4cm}
       \vspace{-2.5cm}
       \begin{align*}
         \hat{\tau} & = 1 + 2 \sum_{t=1}^T \hat{\rho}_t\\
                 & \approx 63
       \end{align*}
        \begin{align*}
         \hat{S}_\text{eff} & = \frac{4500}{63} \approx  71
       \end{align*}
     \end{minipage}
   \end{minipage}
   }

\end{frame}

\section{Difficult geometries}
\frame{\sectionpage}

\begin{frame}

\frametitle{Problematic distributions}

  \begin{itemize}
  \item<1-> Nonlinear dependencies
    \begin{itemize}
    \item optimal proposal depends on location
    \end{itemize}
    \begin{center}
      \href{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=banana}{demo}
    \end{center}
  \item<2-> Funnels
    \begin{itemize}
    \item optimal proposal depends on location
    \end{itemize}
    \begin{center}
      \href{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=funnel}{demo}
    \end{center}
  \item<3-> Multimodal
    \begin{itemize}
    \item difficult to move from one mode to another
    \end{itemize}
        \begin{center}
      \href{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=multimodal}{demo}
    \end{center}
  \item<4-> Non-identifiable models
    \begin{itemize}
    \item set of connected points is the mode
    \end{itemize}
        \begin{center}
      \href{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=donut}{demo}
    \end{center}
  \item<5-> Long-tailed with non-finite variance and mean
    \begin{itemize}
    \item central limit theorem for expectations does not hold
    \end{itemize}

  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
