%\documentclass[10pt,handout]{beamer}
\documentclass[10pt]{beamer}
\usepackage{babel} % Anpassa efter svenska. Ger svensk logga.
\usepackage[utf8]{inputenc} % Anpassa efter linux
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
%\input{../common/lststan} % Stan listing
\usepackage{lstbayes}
\usepackage[all,poly,ps,color]{xy}


\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage{../common/beamerthemeUppsala}
%\usetheme{Uppsala}
%\usecolortheme{UU} % Anpassa efter UU:s frger och logga
%\hypersetup{pdfpagemode=FullScreen} % Adobe Reader ska ppna fullskrm
\setbeamertemplate{itemize items}[circle]

% \usepackage{beamerthemesplit}
\usepackage{amsmath,amsfonts,amssymb}
% \usepackage{amssymb}
% \usepackage{graphics}
% \usepackage{graphicx}
% \usepackage{epsfig}
% \usepackage[latin1]{inputenc}
 \usepackage{color}
% \usepackage{fancybox}
% \usepackage{psfrag}
% \usepackage[english]{babel}
 \setbeamertemplate{footline}{\hfill\insertframenumber/\inserttotalframenumber}

% Input new commands
\input{../common/commands.tex}

\def\dashxy(#1){%
  /xydash{[#1] 0 setdash}def}
\def\grayxy(#1){%
  /xycolor{#1 setgray}def}
\newgraphescape{D}[1]{!{\ar @*{[!\dashxy(2 2)]} "#1"}}
\newgraphescape{P}[1]{!{\ar "#1"}}
\newgraphescape{F}[1]{!{*+=<2em>[F=]{#1}="#1"}}
\newgraphescape{O}[1]{!{*+=<2em>[F]{#1}="#1"}}
\newgraphescape{V}[1]{!{*+=<2em>[o][F]{#1}="#1"}}
\newgraphescape{B}[3]{!{{ "#1"*+#3\frm{} }.{ "#2"*+#3\frm{} } *+[F:!\grayxy(0.75)]\frm{}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength{\parskip}{3mm}
\title[]{{\color{black}Bayesian Statistics and Data Analysis \\ Lecture 8a}}
\author[]{M{\aa}ns Magnusson \\ Department of Statistics, Uppsala University \\ Thanks to Aki Vehtari, Aalto University}
\date{}

\begin{document}

\frame{\titlepage
% \thispagestyle{empty}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Model Checking and Assessment}
\frame{\sectionpage}



\begin{frame}{The Box process: Probabilistic modeling}

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figs/Boxs_loop.png}
    \caption{The Box approach (Box, 1976, Blei, 2014)}
\end{figure}
\end{frame}

\begin{frame}

\frametitle{Model assessment}

  \begin{itemize}
  \item<+-> Sensibility with respect to additional information not used in model
    \begin{itemize}
    \item e.g., if posterior would claim that hazardous chemical
      decreases probability of death
    \end{itemize}
  \item<+-> External validation
    \begin{itemize}
    \item compare predictions to completely new observations
%    \item cf. relativity theory predictions
    \end{itemize}
  \item<+-> Internal validation
    \begin{itemize}
    \item posterior predictive checking
    \item cross-validation predictive checking
    \end{itemize}
  \end{itemize}

\end{frame}

\section{Posterior predictive checking}
\frame{\sectionpage}

\begin{frame}[fragile]
\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Newcombs speed of light measurements
    \begin{itemize}
    \item model $y \sim \N(\mu,\sigma)$ with prior $(\mu, \log \sigma) \propto 1$
    \end{itemize}
  \item<2-> Posterior predictive replicate $y^{\rm rep}$
    \begin{itemize}
    \item<3-> draw $\mu^{(s)},\sigma^{(s)}$ from the posterior $p(\mu,\sigma|y)$
    \item<4-> draw $y^{\mathrm{rep}\,(s)}$ from $\N(\mu^{(s)},\sigma^{(s)})$
    \item<5-> repeat $n$ times to get $y^{\mathrm{rep}}$ with $n$ replicates\\~\\
    \uncover<6->{\includegraphics[width=7cm]{figs/light_ppc_1hist.pdf}}
      \end{itemize}
    \end{itemize}

\end{frame}


\begin{frame}

\frametitle{Replicates vs. future observation}

  \begin{itemize}
  \item Predictive $\tilde{y}$ is the next not yet observed possible
    observation. \pause
    % TODO: Add predictive distribution here
    \item $y^{\mathrm{rep}}$ refers to replicating the \uured{whole
    experiment} (potentially with same values of $x$)\\i.e. obtaining as
    many replicated observations as in the original data.
    % TODO: Double check that y^rep is also a predictive distribution
  \end{itemize}

\end{frame}


\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Generate replicated datasets $y^{\rm rep}$
  %\item<2-> Commonly done using Monte Carlo draws
  % TODO: Double check how yrep is draw (ie using monte carlo draws)
  \item<2-> Compare to the original dataset
  \end{itemize}
  \vspace{-1\baselineskip}
  \uncover<3->{\includegraphics[width=9cm]{figs/light_ppc_10hist.pdf}}

\end{frame}


\begin{frame}

\frametitle{Posterior predictive checking with test statistic}

  \begin{itemize}
  \item Replicated data sets $y^{\rep}$
  \item Test quantity (or discrepancy measure) $T(y,\theta)$
    \begin{itemize}
    \item summary quantity for the observed data $T(y,\theta)$
    \item summary quantity for a replicated data $T(y^{\rep},\theta)$
    \item can be easier to compare summary quantities ($y^{\rep}$ statistics) than data sets
    \end{itemize}
  \end{itemize}

\end{frame}

% TODO: Define test statistic here from the book.

\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Compute test statistic for data $T(y,\theta)=\min(y)$
  \item<2-> Compute test statistic $\min(y^{\rm rep})$ for many replicated datasets
  \end{itemize}
  \vspace{-1.5\baselineskip}
  \uncover<3->{\includegraphics[width=9cm]{figs/light_ppc_min.pdf}}

\end{frame}


\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Good test statistic is \href{https://en.wikipedia.org/wiki/Ancillary_statistic}{ancillary} (or almost)
    \begin{itemize}
    \item a statistic $T(X)$ that does not depend on the parameters of the model are ancillary\\e.g. in a normal model with \uured{known} $\sigma^2$,
    \[
    s^2 = \sum_i^n \frac{(x_i-\bar{x})^2}{n-1}\,,
    \]
    is ancillary ($\mu$ cancel out).
    \item So is the (interquantile) range
    \end{itemize}
  \item<2-> Bad test statistic is highly dependent of the parameters
    \begin{itemize}
    \item e.g. variance (or mean) for normal model with \uured{unknown} $\sigma^2$. If $\sigma^2$ changes so will $T(X)$.
    \end{itemize}
  \item<3-> We want to \uured{identify problems} in data not captured by the \uured{model}
  \end{itemize}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \includegraphics[width=9cm]{figs/light_ppc_var.pdf}

\end{frame}


\begin{frame}[fragile]

\frametitle{Posterior predictive $p$-value}

  \begin{itemize}
  \item<1-> \textit{Posterior predictive $p$-value}
    \begin{eqnarray*}
      p & = & \Pr(T(y^{\rep},\theta)\geq T(y,\theta)|y)\\
      & = & \int\int
      I_{T(y^{\rep},\theta)\geq T(y,\theta)}p(y^{\rep}|\theta)p(\theta|y)dy^{\rep}d\theta
    \end{eqnarray*}
    where $I$ is an indicator function
    \begin{itemize}
    \item<2-> having $(y^{\rep\,(s)},\theta^{(s)})$ from the posterior predictive
      distribution (Monte Carlo):
      \begin{equation*}
        T(y^{\rep (s)},\theta^{(s)})\geq T(y,\theta^{(s)}), \quad s=1,\ldots,S
      \end{equation*}
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \item<3-> Posterior predictive $p$-value (ppp-value):\\
    \uured{could difference between the model and data  arise by chance}
  \item<4-> Not commonly used, since the distribution of test
    statistic $T(y,\theta)$ has more information
  \end{itemize}

\end{frame}

% TODO: Add the special case when thtea is know then, p values follows a uniform distributions. See book.
\subsection{Marginal Predictive Checking}
\frame{\subsectionpage}


\begin{frame}[fragile]

\frametitle{Marginal and CV predictive checking}

  \begin{itemize}
  \item Consider marginal predictive distributions $p(\tilde{y}_i|y)$
    and each observation separately
    \begin{itemize}
    \item marginal posterior p-values
      \begin{align*}
        p_i = \mbox{Pr}(T(y_i^{\rep}) \leq T(y_i) | y)
      \end{align*}
      \pause
    \item<2-> if $T(y_i)=y_i$
      \begin{align*}
        p_i = \mbox{Pr}(y_i^{\rep} \leq y_i | y)
      \end{align*}
    \end{itemize}
  \item<2-> if $Pr(\tilde{y}_i|y)$ well calibrated, distribution of $p_i$
    would be uniform between 0 and 1
    \begin{itemize}
    \item holds better for cross-validation predictive tests: $Pr(\tilde{y}_i|y_{-i})$
      (cross-validation)
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}[fragile]

\frametitle{Marginal predictive checking - Example}

  \begin{itemize}
  \item Marginal tail area or Probability integral transform (PIT)
    \begin{align*}
      p_i = p(y_i^{\rep} \leq y_i | y)
    \end{align*}
  if $p(\tilde{y}_i|y)$ is well calibrated, distribution of $p_i$'s
    would be uniform between 0 and 1
  \end{itemize}
  \vspace{-1.5\baselineskip}
  \uncover<2->{\includegraphics[width=9cm]{figs/light_ppc_pit.pdf}}

\end{frame}


\subsection{Sensitivity analysis}
\frame{\subsectionpage}

\begin{frame}

\frametitle{Sensitivity analysis}

  \begin{itemize}
  \item How much different choices in model structure and priors affect the results
    \begin{itemize}
      \item<2-> test different models and priors
      \item<3-> alternatively combine different models to one model
        \begin{itemize}
        \item e.g. hierarchical model instead of separate and pooled
        \item e.g. $t$ distribution contains Gaussian as a special case
      \end{itemize}
      \item<3-> robust models are good for testing sensitivity to ``outliers''
        \begin{itemize}
        \item e.g. $t$ instead of Gaussian
        \end{itemize}
    \end{itemize}
    \item<4-> Compare sensitivity of essential inference quantities
      \begin{itemize}
      \item extreme quantiles are more sensitive than means and medians
      \item extrapolation is more sensitive than interpolation
      \end{itemize}
    \end{itemize}

\end{frame}

\subsection{Example}
\frame{\subsectionpage}


\begin{frame}

\frametitle{Example: Exposure to air pollution}

  \begin{itemize}
  \item Example from Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael
    Betancourt, and Andrew Gelman (2019). Visualization in Bayesian
    workflow. \url{https://doi.org/10.1111/rssa.12378}
  \item Estimation of human exposure to air pollution from particulate
    matter measuring less than 2.5 microns in diameter ($\mathrm{PM}_{2.5}$)
    \begin{itemize}
    \item Exposure to $\mathrm{PM}_{2.5}$ is linked to a number of
      poor health outcomes and a recent report estimated that
      $\mathrm{PM}_{2.5}$ is responsible for three million deaths
      worldwide each year (Shaddick et al., 2017)
    \item In order to estimate the public health effect of ambient
      $\mathrm{PM}_{2.5}$, we need a good estimate of the
      $\mathrm{PM}_{2.5}$ concentration at the same spatial resolution
      as our population estimates.
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}

  \begin{itemize}
  \item Direct measurements of PM 2.5 from ground monitors at 2980
    locations
  \item High-resolution satellite data of aerosol optical depth
  \end{itemize}
  \begin{center}
    \only<1>{\vspace{-1.8\baselineskip}\includegraphics[height=6cm]{figs/map-data.png}}
    \only<2>{\vspace{-1.8\baselineskip}\includegraphics[height=6cm]{figs/plot1.png}}
    \only<3>{\hspace{-3cm}\includegraphics[height=5.55cm]{figs/plot2.png}}
\end{center}
\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}

  \begin{itemize}
  \item Three models:
  \begin{enumerate}
  \item Linear regression
  \[
  y_{ij} \sim N(\beta_0 + \beta_1 x_{ij}, \sigma^2)
  \]
  \item Hiearchical linear regression (WHO super regions)
  \item Hiearchical linear regression (clustered super regions)
  \[
  y_{ij} \sim N(\beta_0 \beta_{0j} + (\beta_1 + \beta_{1j}) x_{ij}, \sigma^2)
  \]
  \end{enumerate}
  where $y_{ij}$ is the log of $\text{PM}_{2.5}$ concentration and $x_{ij}$ is the satellite estimate, and $j \in \{1,...,J \}$ is the super-region indicator.
  \end{itemize}
\end{frame}


\begin{frame}

\frametitle{Example: Prior predictive checking}

  \begin{center}
    \only<1>{\includegraphics[width=8cm]{figs/pm25_pp1a.pdf}}
    \only<2>{\includegraphics[width=8cm]{figs/pm25_pp1b.pdf}}
    \only<3>{\includegraphics[width=8cm]{figs/pm25_pp2.pdf}}
\end{center}
\end{frame}

\begin{frame}

\frametitle{Example: Marginal predictive distributions}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figs/ppc_dens1.png}
\caption{Model 1}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{Example: Marginal predictive distributions}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figs/ppc_dens2.png}
\caption{Model 2}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{Example: Marginal predictive distributions}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figs/ppc_dens3.png}
\caption{Model 3}
\end{figure}

\end{frame}


\begin{frame}
\frametitle{Example: Test statistic (skewness)}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figs/ppc_skew1.png}
\caption{Model 1}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{Example: Test statistic (skewness)}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figs/ppc_skew2.png}
\caption{Model 2}
\end{figure}


\end{frame}

\begin{frame}
\frametitle{Example: Test statistic (skewness)}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figs/ppc_skew3.png}
\caption{Model 3}
\end{figure}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
